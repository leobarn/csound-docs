<html>	<head>		<meta http-equiv="content-type" content="text/html;charset=iso-8859-1">		<meta name="generator" content="Adobe GoLive 4">		<title>Dear Richard</title>	</head>	<body bgcolor="white">		<div align="left">			<h1><b>23. Multi-band Processing with Time-Varying Filters.</b></h1>			<h2>Rajmil Fischman</h2>			<p><b>Introduction</b></p>			<p>The present chapter discusses processing techniques for the dynamic shaping of spectral components using a bank of time-varying band-pass filters. This is the result of the combination and subsequent formal development of two processes originally devised by J. C. Risset. The first type of process consists of the addition of signals with fundamentals which are slightly detuned in relation to each other, which results in pulsating harmonics originating from difference tones (Dodge and Jerse, 1985:101-2). This technique was used to generate some of the sound material of <i>Inharmonique</i> (Risset, 1977). The second type consists of a subtractive method which uses resonant filters tuned to specific pitches to filter natural sounds (Risset, 1991: 32). These were used in <i>Sud</i> (Risset, 1985).</p>			<p>At first sight, the relationship between the processes above may appear to be purely phenomenological, based on the fact that in both cases one hears pulsating harmonics. However, it will be shown below that both are realizations of the same mathematical principle. This relationship will prove useful as a basis from which a generalized process - derived from the subtractive approach in order to obtain independent control of the various parameters of each pulsating stream - may be devised. Subtractive synthesis offers an additional advantage which contributes to spectral sophistication and variety: the pulsating streams may retain the gestural characteristics of the sound source, thus creating a &#145;shadow&#146; or &#145;ghost&#146; of the original input. Because of this fact, a relatively simple Csound implementation is used to produce articulated morphologies resulting from the input source with spectral characteristics shaped by a filter bank. The number of filters is determined by the requirements of a particular process. Finally, the modular nature of this technique makes it ideal for use in real time, in view of the possibilities opened by the development of Extended Csound.</p>			<p><b>Additive case</b></p>			<p><b>Theoretical background</b></p>			<p>We will begin by establishing the mathematical premises for the additive case, based on the difference tones which result from adding of two sinusoidals.</p>			<p>If <i>f<sub>1</sub></i> and <i>f<sub>2</sub></i> are the frequencies of two sinewaves, addition will produce the following signal</p>			<p><img height="20" width="148" src="Microsoft%20Word%20%201.gif"> (1)</p>			<p>Applying the trigonometric identity for the sum of two sines, we obtain<br>			<img height="32" width="209" src="Microsoft%20Word%20%202.gif">(2)</p>			<p>If the (<i>f<sub>1</sub></i> - <i>f<sub>2</sub></i>)/2 is below the auditory range (&lt; ca. 20 Hz) , equation (2) will describe a sine of frequency (<i>f<sub>1</sub></i> + <i>f<sub>2</sub></i>)/2 pulsating at a rate determined by half the difference of these frequencies. The shape of each pulsation is that of a cosine. Its period is inversely proportional to its frequency, therefore, since a cosine period contains two peaks, a pulsation will last</p>			<p><img height="38" width="244" src="Microsoft%20Word%20%203.gif"> (3)</p>			<p>Figure 1 shows a waveform resulting from adding sinewaves of 100 Hz and 108 Hz. This produces a 104 Hz cosine pulsating 8 times in one second (8 Hz). Each pulsation lasts 0.125 seconds.</p>			<p><img height="92" width="331" src="Microsoft%20Word%20%204.gif"><b><br>			Figure 1</b></p>			<p>Pulsations produced by addition of 100 Hz and 108 Hz sinewaves</p>			<p>Careful choice of frequencies allows control over the duration of the envelope. If the difference <i>f<sub>1</sub></i> - <i>f<sub>2</sub></i> is very small, a pulsation will last several seconds and the detuning of the audible frequency will be negligible. For example. 100 Hz and 100.04 Hz will produce an envelope with pulsations lasting 20 seconds each and an audible sinewave of 100.02 Hz; therefore, the latter is only detuned by 0.02%. This is well below the just noticeable difference (jnd) for human hearing, which ranges from 3% at 100 Hz to 0.5% at 2000 Hz (Dodge and Jerse, 1985: 36).</p>			<p>The case of two sinusoidals may now be extended to more complex signals by addition of harmonics. If we add a second harmonic to each of the sinusoidals above (2<i>f<sub>1</sub></i> and 2<i>f<sub>2</sub></i>), we will obtain the following difference tones:</p>			<p>(<i>f<sub>1</sub></i> + <i>f<sub>2</sub></i>)/2 and (<i>f<sub>1</sub></i> - <i>f<sub>2</sub></i>)/2 from the interaction of <i>f<sub>1</sub></i> and <i>f<sub>2</sub></i>.</p>			<p>(2<i>f<sub>1</sub></i> + 2<i>f<sub>2</sub></i>)/2 and (2<i>f<sub>1</sub></i> - 2<i>f<sub>2</sub></i>)/2 = <i>f<sub>1</sub></i> - <i>f<sub>2 </sub></i>from the interaction of 2<i>f<sub>1</sub></i> and 2<i>f<sub>2</sub></i>.</p>			<p>(<i>f<sub>1</sub></i> + 2<i>f<sub>2</sub></i>)/2 and (<i>f<sub>1</sub></i> - 2<i>f<sub>2</sub></i>)/2 from the interaction of <i>f<sub>1</sub></i> and 2<i>f<sub>2</sub></i>.</p>			<p>(2<i>f<sub>1</sub></i> + <i>f<sub>2</sub></i>)/2 and (2<i>f<sub>1</sub></i> - <i>f<sub>2</sub></i>)/2 from the interaction of 2<i>f<sub>1</sub></i> and <i>f<sub>2</sub></i>.</p>			<p>Assuming that <i>f<sub>1</sub></i> and <i>f<sub>2</sub></i> are in the auditory range and that <i>f<sub>1</sub></i> - <i>f<sub>2</sub></i> is very small, the last two combinations will produce two frequencies which are both in the auditory range - roughly <i>f<sub>1</sub></i> (~ <i>f<sub>2</sub></i>) and 1.5<i>f<sub>1</sub></i> (~ 1.5<i>f<sub>2</sub></i>)<sup>1</sup>. This will be perceived as a modulated signal of constant amplitude. On the other hand, the first two terms will produce pulsating patterns. Furthermore, the second harmonic combination will pulsate at a rate <i>f<sub>1</sub></i> - <i>f<sub>2</sub></i> which is twice as fast than that of the combination of fundamentals, given by (<i>f<sub>1</sub></i> - <i>f<sub>2</sub></i>)/2. This means that peak amplitudes will be reached at different moments: when the fundamentals are loud, the pulsations of the second harmonics will not be heard and vice versa. This is illustrated in figure 2.</p>			<p>The overall result of the combination above will be a drone - resulting from the interaction of first and second harmonics - and pulsations of pure sinusoidals resulting from the interaction of harmonics of the same order (first with first and second with second). For example, the interactions of signals with fundamentals of 100 Hz and 100.04 Hz and two harmonics will produce the following:</p>			<p>100.02 Hz sinusoidal with a 20 second envelope (pulsation).</p>			<p>200.04 Hz sinusoidal with a 10 second envelope (pulsation).</p>			<p>150.02 Hz modulated by 50.02 Hz (drone).</p>			<p>150.01 Hz modulated by 49.98 Hz (drone).</p>			<p>&nbsp;<img height="122" width="257" src="Microsoft%20Word%20%205.gif"></p>			<p><b>Figure 2</b></p>			<p>Pulsations produced by harmonics of the same order. (A) <i>f<sub>1</sub></i> and <i>f<sub>2</sub></i>. (B) 2<i>f<sub>1</sub></i> and 2<i>f<sub>2</sub></i>.</p>			<p>It is now possible to generalize this process to <i>m</i> signals with <i>n</i> harmonics and fundamentals which are very close to each other:</p>			<ol>				<li>For every pair of signals, the interactions of harmonics of different order will contribute to the drone.				<li>For every pair of signals, the interactions of harmonics of the same order will produce pulsations of sinusoidals. If the signals have <i>n</i> harmonics, the number of pulsations of different rate will be <i>n</i>. The period of each pulsation may be obtained by replacing the appropriate frequencies in equation (3).				<li>If <i>m</i> signals with different fundamentals are mixed the total number of pulsations will be given by the product of the total number of combined pairs multiplied by the number of pulsations for each combination.			</ol>			<p>The total number of possible pairs given a total of <i>m</i> signals is</p>			<p><img height="45" width="95" src="Microsoft%20Word%20%206.gif"></p>			<p>therefore, the total number of different pulsations for <i>m</i> signals with <i>n harmonics </i>is</p>			<p><img height="45" width="136" src="Microsoft%20Word%20%207.gif">(4)</p>			<p><b>Csound implementation</b></p>			<p>Implementation of the additive case requires a simple oscillator with an envelope. The oscillator is invoked in the score using an instrument statement. The complexity of the waveform is determined by a score function table generated with GEN10, which produces harmonic spectra. The orchestra MB1.ORC consists of the following instrument and is similar to the realization of Risset&#146;s original instrument.</p>			<p>instr 1</p>			<p>;-----------------------------------;BLOCK INITIALIZATION<br>			idur = p3 ;duration<br>			iamp = p4 ;amplitude<br>			ifreq = p5 ;frequency<br>			iatt = p6 ;attack<br>			idec = p7 ;decay<br>			ifunc = p8 ;function table</p>			<p>;--------------------------------------------------</p>			<p>kenv linen iamp,iatt,idur,idec ; envelope<br>			aout oscili kenv,ifreq,ifunc ; oscillator<br>			out aout<br>			endin</p>			<p>The duration, amplitude, fundamental, attack, decay and function table of the generated signal are given by parameters <i>p3</i> to <i>p8</i>, stored respectively in variables <i>idur</i>, <i>iamp</i>, <i>ifreq</i>, <i>iatt</i>, <i>idec</i> and <i>ifunc</i>. The envelope is generated with a linen statement and the oscillator is realized using OSCILI.</p>			<p>The score MB1.SCO performs addition of 11 signals with 20 harmonics each. The fundamentals are spaced in steps of 0.025 Hz above and below 70 Hz, resulting in the following frequencies: 69.875, 69.9, 69.925, 69.95, 69.975, 70, 70.025, 70.05, 70.075, 70.1 and 70.125 Hz. Replacing 0.025 Hz (= <i>f<sub>1 </sub></i>- <i>f<sub>2</sub></i>) in equation 3, it is possible to obtain the longest pulsation period, which is 40 seconds. The generating function for a waveform with 20 harmonics is</p>			<p>f1 0 8192 10 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</p>			<p>A single oscillator requires an <i>i1</i> statement. For example, the 70 Hz oscillator is realized as follows:</p>			<p>; p3 p4 p5 p6 p7 p8</p>			<p>;instr start dur amp fund attack decay function</p>			<p>i1 0 25 3000 70 0.1 3.5 1</p>			<p>It should be noted that the function table f1 consists of harmonics of equal amplitudes. Using different function tables one may emphasize harmonic regions, creating formants. For example, MB2.ORC and MB2.SCO employ an instrument identical to <i>instr1</i> in order to synthesize the same number of signals with the same fundamentals used in example 1; however, in this case, higher harmonics are emphasized by means of the following function table.</p>			<p>f1 0 8192 10 .05 .1 .15 .2 .25 .3 .35 .4 .45 .5 .55 .6 .65 .7 .75 .8</p>			<p>.85 .9 .95 1</p>			<p><b>Subtractive Realization</b></p>			<p>We will now proceed to model the same type of pulsating harmonics using a subtractive synthesis representation</p>			<p><b>Theoretical background</b></p>			<p>In order to deduce the subtractive model, it may be useful to examine the sound produced with MB1.SCO. The signals may be arranged according to their fundamentals as follows:</p>			<p>70.125 Hz = 70 + 0.125 = 70 + 5 x 0.025</p>			<p>70.1 Hz = 70 + 0.1 = 70 + 4 x 0.025</p>			<p>70.075 Hz = 70 + 0.075 = 70 + 3 x 0.025</p>			<p>70.05 Hz = 70 + 0.05 = 70 + 2 x 0.025</p>			<p>70.025 Hz = 70 + 0.025 = 70 + 1 x 0.025</p>			<p><b>70</b> Hz</p>			<p>69.975 Hz = 70 - 0.025 = 70 - 1 x 0.025</p>			<p>69.95 Hz = 70 - 0.05 = 70 - 2 x 0.025</p>			<p>69.925 Hz = 70 - 0.075 = 70 - 3 x 0.025</p>			<p>69.9 Hz = 70 - 0.1 = 70 - 4 x 0.025</p>			<p>69.875 Hz = 70 - 0.125 = 70 - 5 x 0.025</p>			<p>This may now be generalized for any number of signals with fundamentals above and below a frequency <i>f</i> with differences which are multiples of a step <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"><i>f</i>.</p>			<p>f + n x <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f, ... f + 2 x <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f, f + 1 x <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f, <b>f</b>, f - 1 x <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f, f - 2 x <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f, ... f - n x<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f</p>			<p>Adding only the fundamentals of the signals produces an output described by the following equation</p>			<p><img height="37" width="305" src="Microsoft%20Word%20%208.gif">(5)</p>			<p>Applying the trigonometric identity for the sum of two sines to every term in (5) we obtain</p>			<p><img src="Microsoft%20Word%20%209.gif" width="233" height="80"> (6)</p>			<p>Equation (6) represents a sinewave of frequency <i>f</i> which is modulated by a sum of cosines with frequencies <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> <i>f</i>, 2<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> <i>f</i>, ... <i>n<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f</i>Hz - indicated by the expression in square brackets - and a constant. If <img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> <i>f</i> is very small so that <i>n<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f</i>is below the auditory range - (e.g. 0.025 Hz in the example above) the effect of the cosine sum is that of an envelope.</p>			<p>In a similar fashion, adding second harmonics will produce the expression</p>			<p><img src="Microsoft%20Word%2010.gif" width="235" height="54"> (7)</p>			<p>which represents the second harmonic of <i>f</i> multiplied by an envelope of the same shape and a period which is half of the duration of the period resulting from addition of the fundamentals.</p>			<p>Finally, generalizing for the addition of harmonics of order <i>j</i>, we obtain</p>			<p><img src="Microsoft%20Word%2011.gif" width="235" height="46"> (8)</p>			<p>which represents the <i>j</i>th harmonic of <i>f</i> , multiplied an envelope which has the same shape and 1/<i>j</i>th of the fundamental period.</p>			<p>The overall output consists of the sum of terms <i>o<sub>j</sub>(t)</i></p>			<p><img src="Microsoft%20Word%2012.gif" width="295" height="46"> (9)</p>			<p>Equation (9) represents a set of sinewaves, each with an envelope given by the expression in square brackets. The sum of cosines contributes to the pulsations while the constant contributes to the drone.</p>			<p><b>Csound Implementation</b></p>			<p>The waveform in equation (9) may be realized by means of a filter bank in which the gain of each filter is a function of time. The source for this process must be rich in harmonics; therefore, the present implementation uses a train of pulses which contains harmonics within the band-pass of the filters. Since the fundamental of a train of pulses determines the spectral spacing of the harmonics, this requisite may be met using a fundamental frequency which is equal or less than the desired spacing between harmonics.</p>			<p>The envelope of each filter may be generated in the score using GEN9, which represents a sum of sinusoidals with any harmonic ratio, amplitude and phase. Setting the phase to 90<sup>o</sup> produces cosines; setting the frequency ratio to 0 produces a constant. For example, the following function will produce an envelope resulting from adding 3 harmonics:</p>			<p>;# start size GEN9 1 +cos(2_<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> ft)+cos(2_ 2<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f t)+cos(2_ 3<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f t)</p>			<p>f1 0 2048 9 0 1 90 1 2 90 2 2 90 3 2 90</p>			<p>The following instrument, included in MB3.ORC, implements a single time-varying filter with a train of pulses as input.</p>			<p>instr 3</p>			<p>;-----------------------------;INITIALIZATION BLOCK</p>			<p>idur = p3 ;duration iampf = p4 ;scaling amplitude factor<br>			iatt = p5 ;overall attack<br>			idec = p6 ;overall decay<br>			itpamp = 20000 ;pulse amplitude<br>			itpfreq = p7 ;pulse fundamental<br>			itpharm = p8 ;pulse number of harmonics<br>			itpfunc = p9 ;pulse function table<br>			ipeamp = 1.00 ;pulsation normalized amplitude<br>			ipefreq = p10 ;pulsation frequency<br>			ipefunc = p11 ;pulsation envelope function table<br>			icfreq = p12 ;filter center frequency<br>			ibw = p13 ;filter bandwidth<br>			iampbal = 1 ;filter power balancing<br>			;----------------------------------------------------<br>			kpenv oscil ipeamp,ipefreq,ipefunc ;pulsation envelope<br>			kenv linen iampf,iatt,idur,idec ;overall envelope<br>			kenv = kenv*kpenv ;multiply envelopes<br>			ain buzz itpamp,itpfreq,itpharm,itpfunc ;train of pulses<br>			afilt reson ain,icfreq,ibw,iampbal ;filter<br>			out kenv*afilt ;output<br>			endin</p>			<p>The center frequency and bandwidth are given by <i>p12</i> and <i>p13</i> and stored in <i>icfreq</i> and <i>ibw</i>. The variable <i>iampbal</i> indicates the type of scaling used in the filter: a value of 1 scales the peak amplitude of the output so that it matches the peak amplitude of the input. This is not always enough, because RESON assumes that all frequencies are physically present, which is only true in the case of white noise. Therefore, the orchestra contains an additional scaling factor controlled by <i>p4</i> and stored in <i>iampf</i>. The actual value of <i>iampf</i> depends on the spectral content of the input and the filter frequency and bandwidth, requiring some experimentation and fine tuning. The overall duration, attack and decay of the output are given by <i>p3</i>, <i>p5</i> and <i>p6</i>, and stored respectively in variables <i>idur</i>, <i>iatt</i> and <i>idec</i>. These produce a LINEN envelope with amplitude determined by <i>iampf</i>. The filter envelope is produced with OSCIL, creating the control signal <i>kpenv</i>, which is subsequently multiplied by the output of the LINEN statement (<i>kenv</i>) in order to avoid clicks. Its amplitude is normalized to 1.00 and given by <i>ipeamp</i>. The pulsation frequency (number of pulsations per second) and function table number are stored in <i>ipefreq</i> and <i>ipefunc</i>. The former is given by <i>p10</i>; the latter by <i>p11</i>.</p>			<p>The train of pulses is generated using a BUZZ statement with <i>itpamp</i>, <i>itpfreq</i>, <i>itpharm</i> and <i>itpfunc</i> storing the pulse amplitude (set arbitrarily to an amplitude of 20000), fundamental frequency (<i>p7</i>), number of harmonics (<i>p8</i>) and the function table (<i>p9</i>). Finally, the output of BUZZ, <i>ain</i>, is fed to a RESON band-pass filter, with center frequency given by <i>p12</i> and stored in <i>icfreq</i>, and bandwidth given by <i>p13</i> and stored in <i>ibw</i>. The output of the filter is multiplied by the overall envelope.</p>			<p>The score MB3.SCO implements a bank of 15 filters (each filter is represented by an instrument statement) with center frequencies ranging from 100 Hz to 1500 Hz in steps of 100 Hz. The bandwidth is always 1 Hz. The envelope of each filter is implemented in function 4, which is generated with GEN9 and corresponds to equation (8), when <i>n</i>=15.</p>			<p>f4 0 2048 9 0 1 90 1 2 90 2 2 90 3 2 90 4 2 90 5 2 90 6 2 90 7 2 90 8 2 90 9 2 90 10 2 90 11 2 90 12 2 90 13 2 90 14 2 90 15 2 90</p>			<p>It should be noticed that the number of pulsations per second, determined by the frequency of the filter envelope, becomes faster for higher frequencies - ranging from 0.03 Hz (<i>T<sub>p</sub></i> = 33.33 sec.) to 0.45 Hz (<i>T<sub>p</sub></i> = 2.22 sec.)</p>			<p>The generating function for the train of pulses is a sinewave, implemented in function 3.</p>			<p>f3 0 8192 10 1</p>			<p>Each filter in the bank is invoked by means of an <i>i3</i> statement. For example, the statement below invokes a filter which starts processing a train of pulses at time 0 and lasts 25 beats. Its center frequency (<i>p12</i>) is 100 Hz and the bandwidth (<i>p13</i>) is 1 Hz. Its output is shaped with an envelope produced at a rate (<i>p10</i>) of 0.03 Hz with its shape determined by function 4 (<i>p11</i>).</p>			<p>; p3 p4 p5 p6 p7 p8 p9 p10 p11 p12 p13</p>			<p>;----------------------------------------------------------------</p>			<p>i3 0 25 25 0.1 3.5 10 250 3 0.03 4 100 1</p>			<p><b>Generalization of Subtractive Case </b></p>			<p>The subtractive method offers possibilities which would otherwise be restricted by an additive procedure. While the latter depends on manipulation of sinewaves with specific relations between their frequencies, the former only requires the existence of the desired output components in the source. The actual spectrum of the output and characteristics of the pulsations may be determined at will by setting the appropriate filter and envelope parameters. We will now proceed to generalize the instrument described in the previous section in order to achieve more versatile and sophisticated processes.</p>			<p><b>Filtering of a Sampled Sound</b></p>			<p>In the first place, it is possible to take advantage of the morphologies of sounds derived from natural sources. In order to implement an instrument which filters an existing set of samples, it is possible to replace the BUZZ generator in MB3.ORC with the Csound statement SOUNDIN. The latter requires a soundfile code, which is either the name of the soundfile containing samples or, alternatively, a three digit number <i>nnn</i>, as long as the name of the soundfile is <i>soundin.nnn</i>. SOUNDIN also allows an optional parameter which indicates how many seconds to skip from the beginning of the soundfile. Therefore, the following line may be used to replace the buzz generator</p>			<p>ain soundin isfcode,isfskip</p>			<p>where <i>isfcode</i> is the soundfile <i>nnn</i> code and <i>isfskip</i> is the number of seconds skipped.</p>			<p><b>Time-Varying Center Frequency and Bandwidth</b></p>			<p>The center frequency and bandwidth of the filters may become a function of time. Filters with time-varying center frequency may be implemented specifying its maximum and minimum values, as well as a function table which describes the time dependency of the fluctuations between maximum and minimum. For example, if the parameters <i>p13</i>, <i>p14</i> represent respectively the minimum and maximum frequencies, the maximum frequency fluctuation will be given by</p>			<p>icffluc = p14-p13</p>			<p>Assuming that the function table number is stored in <i>icffunc</i>, the time-varying fluctuation may be realized with an OSCIL1 statement, which sweeps through <i>icffunc</i> exactly one time throughout the duration of the sound.</p>			<p>kcf oscil1 0,icffluc,idur,icffunc</p>			<p>Also, if the minimum frequency is stored in <i>icfmin</i>, we may add the fluctuation to this variable to obtain the time-varying center frequency.</p>			<p>kcf = icfmin+kcf</p>			<p>The bandwidth may be expressed as a percentage of the center frequency, which allows a simpler implementation of filter banks with constant Q (<img height="11" width="8" src="Microsoft%20Word%20%20A.gif"> f/f = constant). The following set of statements is similar to the set used in the case of the center frequency, and produces a time-varying bandwidth.</p>			<p>ibwmin = p16 ;minimum bandwidth as % of center frequency</p>			<p>ibwfluc = p17-p16 ;filter bandwidth fluctuation (% of center freq)</p>			<p>ibwfunc= p18 ;filter bandwidth function</p>			<p>:</p>			<p>:</p>			<p>kbw oscil1 0,ibwfluc,idur,ibwfunc ;filter bandwidth</p>			<p>kbw = (ibwmin+kbw)*kcf/100.0</p>			<p><b>Pulsation envelope and frequency</b></p>			<p>Since the envelope of the pulsation is generated independently from the filter, it is possible to substitute the function in equation (8) by any other shape, specified by a function table in the score. Also, in contrast to the additive case, the frequency of the pulsations (number of pulsations per second) is not dependent on other parameters and may become a function of time. The following lines are used to produce pulsations with any envelope and time-varying frequency.</p>			<p>ipfmin = p9 ;minimum pulsation frequency</p>			<p>ipffluc = p10-p9 ;pulsation frequency fluctuation</p>			<p>ipffunc = p11 ;pulsation frequency fluctuation function</p>			<p>ipefunc = p12 ;pulsation envelope function</p>			<p>:</p>			<p>:</p>			<p>kpfreq oscil1 0,ipffluc,idur,ipffunc ;pulsation frequency variation</p>			<p>kpfreq = ipfmin+kpfreq</p>			<p>kpenv oscil ipeamp,kpfreq,ipefunc ;pulsation envelope</p>			<p>MB4.ORC consists of an instrument which filters a soundfile, implementing a filter with time-varying frequency and bandwidth. It also allows configuration of the pulsation envelope and frequency. The score MB4.SCO uses this orchestra in order to process a sampled sound stored in soundfile <i>soundin.1</i> with a bank comprising 11 filters. The center frequency and bandwidth of each filter are time-varying, fluctuating according to functions 7 and 8.</p>			<p>f7 0 4096 7 0 1024 1 1024 0.3 1024 0.8 1024 0.4</p>			<p>f8 0 4096 7 1 1024 0 1024 0.3 1024 0.4 1024 0</p>			<p>The pulsation envelope frequency fluctuates according to function 5 and its envelope is defined by function 6.</p>			<p>f5 0 4096 7 1 4096 0</p>			<p>f6 0 4096 19 1 1 270 1</p>			<p>The frequencies of the filters in the score have inharmonic ratios. Each of the filters is invoked using an instrument statement. For example, the following is a filter with center frequency between 2000 Hz (<i>p13</i>) and 2020 Hz (<i>p14</i>), bandwidth is between 0.1% (<i>p16</i>) and 0.3% (<i>p17</i>) of the instantaneous center frequency and pulsations which oscillate with a minimum frequency (<i>p9</i>) of 0.11 Hz and a maximum (<i>p10</i>) of 0.12 Hz.</p>			<p>; p3 p4 p5 p6 p7 p8 p9 p10 p11 p12 p13 p14 p15 p16 p17 p18</p>			<p>;----------------------------------------------------------------------</p>			<p>i4 0 8.547 70 .001 .005 1 0 .11 .12 5 6 2000 2020 7 .1 .3 8</p>			<p><b>Balanced Output</b></p>			<p>The cases above used an amplitude factor to compensate for power loss due to filtering. It is possible to use an alternative method provided by BALANCE. This statement compares the root mean square (RMS)<sup>2</sup> of the output with that of a reference signal; usually the input source. The amplitude factor may still be kept in order to fine-tune the final gain. MB5.ORC contains an instrument which is a modified version of MB4.ORC carried out by replacing the output statement with the following lines</p>			<p>aout balance afilt,ain ;balance</p>			<p>out kenv*aout ;output</p>			<p>Although BALANCE does not affect the frequency content of the output, in some cases, the temporal characteristics of the latter may be affected so drastically that it begins to resemble the source. This is particularly noticeable in sources with fast transients or quick changing spectra. The effects of balancing an input with fast transients may be appreciated by comparing the sounds generated with MB4.ORC/MB4.SCO with those obtained with MB5.ORC/MB5.SCO (both use <i>soundin.1</i> as their input). The only difference between the scores consists of the use of faster pulsation frequencies in MB5.SCO: these are in the region of 5 Hz to 7.6 Hz, whereas MB4.SCO uses frequencies ranging from 0.11 Hz to 1.32 Hz.</p>			<p><b>Spatial Articulation</b></p>			<p>A further enhancement of the process consists of spatialization of the output of each individual filter.</p>			<p>The panning algorithm employed here has been used in various pieces of software, notably in the PAN program from the <i>Composers&#146; Desktop Project</i> <i>Groucho Sound Processing Programs</i> - originally produced by Bentley (Atkins, Bentley, Endrich, Fischman, Malham, Orton and Wishart 1987; Dobson and Endrich 1994). It assumes a stereo image and uses normalized values to represent panning positions. A value of 1 represents the position of the right speaker, -1 that of the left speaker and 0 is the center. Panning values which are larger than 1 or smaller than -1 are respectively besides the right and left speakers. As a result, the speaker distance is normalized to a value of 2. The listener is located along a line perpendicular to the center and at a distance which is half of the speakers&#146; separation, equivalent to a normalized value of 1. Figure 3 shows a diagram representing the various parameters.</p>			<p>Lets assume that the amplitude of a signal in the center (pan = 0) is <i>A<sub>0</sub></i>. At this point, the distance from the listener is 1. When the position is displaced by <i>x</i> the distance from the listener becomes <img src="Microsoft%20Word%2013.gif" width="34" height="18">, and the amplitude, <i>A<sub>x</sub></i>, is given by the inverse square law</p>			<p><img src="Microsoft%20Word%2014.gif" width="97" height="25"></p>			<p>therefore</p>			<p><img src="Microsoft%20Word%2015.gif" width="75" height="32"> (10)<b><br>			Figure 3 </b></p>			<h3><b>Panning Algorithm Setup</b></h3>			<p><a name="now"></a>In order to normalize the maximum value of the amplitude to 1, we may remember that the energy of a signal is proportional to the square of the amplitude</p>			<p><img src="Microsoft%20Word%2016.gif" width="46" height="18"></p>			<p>Assuming no losses, the law of conservation states that the total energy remains constant. Therefore, the sum of energies produced by each speaker must remain constant.</p>			<p><img height="35" width="101" src="Microsoft%20Word%2017.gif"> (11)</p>			<p>When the signal is in the middle, both speakers produce the same amount of energy, due to the amplitude <i>A<sub>0</sub></i>. Making <i>A<sub>TOTAL</sub></i>=1 and replacing in equation (11), we have</p>			<p><img src="Microsoft%20Word%2018.gif" width="101" height="22"></p>			<p>therefore</p>			<p><img src="Microsoft%20Word%2019.gif" width="50" height="30"> (12)</p>			<p>The distribution between the speakers depends on the position with respect to the center. If the pan value is positive, the signal will be situated at a distance <i>x</i> to the right of the center, otherwise, the position will be to the left of the center. Therefore, if <i>x</i> is the pan value, the relative weight of each speaker will be</p>			<p><img src="Microsoft%20Word%2020.gif" width="77" height="40"></p>			<p>where <i>A<sub>xL</sub></i> and <i>A<sub>xR</sub></i> are, respectively, the left and right speaker amplitudes. As expected, hen <i>x</i> is positive we have <i>A<sub>xR</sub></i> &gt; <i>A<sub>xL</sub></i> and when it is negative <i>A<sub>xL</sub></i> &gt; <i>A<sub>xR</sub></i>. Using this relation and equations (10) and (12), we obtain</p>			<p><img src="Microsoft%20Word%2021.gif" width="87" height="69"> (13)</p>			<p>Similar calculations provide the formulas for positions beside the left speaker</p>			<p><img src="Microsoft%20Word%2022.gif" width="81" height="53"> (<i>x</i>&lt;-1) (14)</p>			<p>and besides the right speaker</p>			<p><img src="Microsoft%20Word%2023.gif" width="81" height="53"> (<i>x</i>&gt;1) (15)</p>			<p>Equations (13) to (15) may be implemented in a Csound orchestra as follows:</p>			<p>imaxpan = p19 ;maximum pan ipfreq = p20 ;pan frequency<br>			ipanfunc= p21 ;pan function table<br>			isr2 = sqrt(2.0) ;square root of 2<br>			isr2b2 = isr2/2.0 ;half of square root of 2<br>			kpan oscili imaxpan,ipfreq,ipanfunc ;panning trajectory<br>			if kpan&lt;-1 kgoto beyondl ;pan beyond left speaker?<br>			if kpan&gt;1 kgoto beyondr ;pan beyond right speaker?<br>			;-------------------------------------;pan between speakers, eqs. (13)<br>			ktemp = sqrt(1+kpan*kpan)<br>			kpleft = isr2b2*(1-kpan)/ktemp<br>			kpright = isr2b2*(1+kpan)/ktemp<br>			kgoto donepan<br>			beyondl: ;pan beyond left speaker, eqs. (14)<br>			kpleft = 2.0/(1+kpan*kpan)<br>			kpright = 0<br>			kgoto donepan<br>			beyondr: ;pan beyond right speaker, eqs. (15)<br>			kpleft = 0<br>			kpright = 2.0/(1+kpan*kpan)<br>			donepan:</p>			<p>The spatial trajectory is implemented using an oscillator with output <i>kpan</i>, which is driven by a function indicating its shape (<i>ipanfunc</i>=<i>p21</i>). The oscillator has a maximum amplitude given by <i>p19</i> and stored in <i>imaxpan</i>, corresponding to the maximum panning value. The panning trajectory may be repeated several times throughout the duration of the event depending on the value of the panning frequency, given by <i>p20</i> and stored in <i>ipanfreq</i> (in order to obtain only one trajectory throughout the event, <i>ipanfreq</i> must be 1/<i>idur</i>, where <i>idur</i> is the duration of the event). The IF ... KGOTO statements test the value of <i>kpan</i> and determine which set of equations should be applied. The variables <i>isr2</i> and <i>isr2b2</i> respectively store the square root of two and half of this value for use with equation (13) to (15).</p>			<p>In order to output stereo, the header variable <i>nchnls</i> must be set to 2. In addition, the output line should use OUTS instead of OUT.</p>			<p>outs kenv*kpleft*aout,kenv*kpright*aout</p>			<p><b>Doppler Effect</b></p>			<p>The algorithm used here is based on that shown in the Csound manual (Vercoe, 1986), which employs a delay line in order to implement Doppler shift according to the following principle: if the signal is at a distance <i>d</i> from the listener, the time it takes a sample to reach the listener is</p>			<p><img src="Microsoft%20Word%2024.gif" width="81" height="30"></p>			<p>where <i>isndsp</i> is the speed of sound in air. Now, if the period of the signal is <i>T</i> (the frequency is <i>f</i> = 1/<i>T</i>) and the first sample of a cycle occurs at time &#153; , the last sample will occur at time &#153; +<i>T</i>. If the signal is stationary, the first and last samples will respectively reach the listener at times</p>			<p><img src="Microsoft%20Word%2025.gif" width="233" height="41"></p>			<p>and the frequency the listener perceives is</p>			<p><img src="Microsoft%20Word%2026.gif" width="140" height="41"></p>			<p>However, if the source moves at a speed <i>v</i>, the distance from the listener when the last sample in the cycle occurs will be <i>d</i>+<i>vT</i>, which means that the last sample will arrive at time</p>			<p><img src="Microsoft%20Word%2027.gif" width="140" height="41"></p>			<p>therefore, the frequency perceived by the listener will be</p>			<p><img src="Microsoft%20Word%2028.gif" width="257" height="59"> (16)</p>			<p>If the signal approaches the listener, <i>v</i> will be negative and, from equation (16), the resulting frequency will be higher than <i>f</i>. Similarly, if the signal departs from the listener, <i>v</i> will be positive and the resulting frequency will be lower than <i>f</i>.</p>			<p>The time it takes a sample to reach the listener may be simulated using a delay line. Also, since the distance from the listener to the line of the speakers is constant, it is only necessary to account for movement along the latter, which is determined by <i>x</i>. If the signal is in the middle position (<i>x</i>=0), the delay should be 0; any other position should generate a delay which is proportional to the absolute value of <i>x</i>. When the signal moves, <i>x</i> changes and, as a result, the delay changes in proportion to the absolute value of <i>x</i>, producing a smooth change in frequency.</p>			<p>The relationship between the delay value and panning may be found as follows: if <i>ihspeakd</i> is the distance between the speakers and the center (half of the speaker distance), and <i>isndsp</i> the speed of sound in air, the time it takes a sample to travel from one speaker to the center is</p>			<p><img src="Microsoft%20Word%2029.gif" width="113" height="43"></p>			<p>This happens when the absolute value of <i>x</i> is 1. Any other value of <i>x</i> represents a scaling of the distance from the speaker to the center, therefore, the delay is also scaled by <i>x</i> and we have</p>			<p><img src="Microsoft%20Word%2030.gif" width="113" height="43"> (17)</p>			<p>Finally, if <i>x</i> changes according to a control signal such as <i>kpan</i>, the delay time <i>kpdel</i> will change in according to</p>			<p><img src="Microsoft%20Word%2031.gif" width="113" height="43"> (18)</p>			<p>A Csound implementation of the Doppler delay line is listed below.</p>			<p>ihspeakd= 5.0 ;half of the distance between speakers (m)</p>			<p>isndsp = 331.45 ;sound speed in air (m/sec)</p>			<p>impandel= imaxpan*ihspeakd/isndsp ;maximum pan delay</p>			<p>kpdel = kpan*ihspeakd/isndsp ;find pan delay</p>			<p>adump delayr impandel ;set maximum</p>			<p>aout deltapi abs(kpdel) ;tap delay according to pan</p>			<p>delayw afilt ;delay signal</p>			<p>The maximum delay is directly proportional to the maximum panning value; therefore, <i>impandel</i> is calculated by direct replacement of <i>imaxpan</i> in equation (17). The time-varying delay is calculated using equation (18). Next, a delay line with a maximum delay time equal to <i>impandel</i> is opened using DELAYR. This line is connected to <i>aout</i> using the statement DELTAPI, which sends each sample after a duration equal to the absolute value of <i>kpdel</i>. Finally, the output of the filter, <i>afilt</i> is fed to the delay line.</p>			<p>MB6.ORC consists of an instrument which implements spatial articulation and Doppler shift using the techniques discussed above. MB6.SCO, processes the soundfile <i>soundin.1</i> with the same filters and envelope parameters used in MB4.SCO. In addition parameters <i>p19</i>, <i>p20</i> and <i>p21</i> determine respectively the maximum pan value, pan frequency (number of repetitions of the panning trajectory) and panning function. All the filter outputs are panned with function table 9; however, the frequency of the panning oscillator is different for each filter.</p>			<p><b>Processing of Stereo Soundfiles</b></p>			<p>Instruments 4 and 5 may be extended so that they process stereo files. In the first place, <i>nchnls</i> must be set to 2 in the header. Next, the SOUNDIN statement must have two outputs</p>			<p>al,ar soundin isfcode,isfskip</p>			<p>Each of these inputs must be filtered and, if required, balanced</p>			<p>afiltl reson al,kcf,kbw,iampbal ;filter left channel</p>			<p>afiltr reson ar,kcf,kbw,iampbal ;filter right channel</p>			<p>aball balance afiltl,al ;balance left channel</p>			<p>abalr balance afiltr,ar ;balance right channel</p>			<p>Finally, the output must use OUTS.</p>			<p>outs kenv*aoutl,kenv*aoutr</p>			<p><b>Cross-Fade of Balanced and Unbalanced Filter Outputs</b></p>			<p>We saw above that carrying out an RMS balance of the output may alter its morphology. It is therefore possible to produce several cross-fades between balanced and the unbalanced versions, achieving more timbral variety. A time-varying cross-fade may be implemented using a function table which drives a single cycle oscillator such as OSCIL1. A high value of the function table may favor one of the states - for instance, the balanced output - whereas a low value may favor the other. The following lines assume that <i>p19</i> determines the function table number, which is subsequently stored in <i>ixfunc</i>. The variable <i>inenv</i> is a normalized amplitude.</p>			<p>inenv = 1.00</p>			<p>ixfunc = p19</p>			<p>kxf oscil1 0,inenv,idur,ixfunc</p>			<p>Assuming that <i>aball</i> and <i>abalr</i> are the stereo outputs of BALANCE and that <i>afiltl</i> and <i>afiltr</i> are the unbalanced outputs of the filters, the cross-fade will be generated multiplying the balanced pair by <i>kxf</i> and the unbalanced pair by (1-<i>kxf</i>).</p>			<p>aoutl = kxf*aball+(1-kxf)*afiltl*iampf</p>			<p>aoutr = kxf*abalr+(1-kxf)*afiltr*iampf</p>			<p>MB7.ORC and MB7.SCO demonstrate a cross-fade process applied to stereo input <i>soundin.2</i>. Because of the nature of the input, the balanced process will generate signals with more prominent attacks, while the unbalanced process will resemble more the &#145;thinner&#146; harmonics.</p>			<p>&nbsp;</p>			<p><b>A Final Example</b></p>			<p>As a final example, a process used in the tape part of the piece <i>The Day After...</i>, for string quartet and tape (Fischman, 1995) will be examined. The input is the sound of a recorded airplane flying past the listener. This sound is followed by the output of a stereo process using 15 filters with center frequencies ranging from 100 Hz to 4731 Hz and bandwidth from 0.5 Hz to 3 Hz. The frequency of the pulsations is in the range of 0.1 Hz to 6.9 Hz, with a frequency fluctuation function which favors the upper range when the airplane approaches the listener. The pulsation envelope is a raised cosine bell.</p>			<p>The next example is the output of a process using similar parameters, except for the shape of the pulsation envelope, which is a short exponential trapezoid. The resulting pulsations tend towards discrete percussive beats. The final example consists of a passage of <i>The Day After...</i>, which uses the sounds above and their transpositions.</p>			<p><b>Conclusion and Further Possibilities</b></p>			<p>The use of multiple time-varying filters which shape synthesized and sampled signals has been discussed in detail. The point of departure consisted of models developed by J. C. Risset for use in his compositional work. Initially, an additive model was simulated using a set of filters with constant center frequency and bandwidth. This was then realized using a subtractive model, which was extended to include time-varying center frequency and bandwidth, time-varying pulsation frequency, balanced output, spatial articulation, Doppler effect, treatment of stereo soundfiles and cross-fades between balanced and unbalanced versions.</p>			<p>The techniques above offer a great range of possibilities which are greatly enhanced by the fact that they take full advantage of the characteristics of the input source; different sounds fed to the same bank of filters will produce different results. Therefore, proper manipulation of the filter parameters may allow the composer to take keep interesting properties of the original source and employ these for the creation of new sonorities.</p>			<p>The processes described in this chapter may be developed further. For example, the panning algorithms may be extended to cope with more than one dimension. In a quadraphonic system, it is possible to use Csound&#146;s PAN statement. If three-dimensional spatialization is required, equations (13) to (15) may also be applied to the movement between rear and front and top and bottom set of speakers using different variables to represent each dimension. It is also possible to generate depth information using two speakers: if <i>y</i> is the normalized distance from a sound behind the speakers to the line of the speakers, equations (13) to (15) may be modified as follows:</p>			<p>equations (13) become</p>			<p><img src="Microsoft%20Word%2032.gif" width="259" height="49"> (20)</p>			<p>equations (14) and (15) become</p>			<p><img src="Microsoft%20Word%2033.gif" width="290" height="85"></p>			<p>Other processes may include the use of non-linear filters, manipulation of spectral regions using Csound&#146;s phase vocoder (PVOC) and associated statements and the application of temporal procedures using the Csound module sndwarp.</p>			<p>Finally, the modularity and relative simplicity of the filter bank technique makes it ideal for real time implementation, especially in view of the possibilities offered by Extended Csound. It is therefore feasible to envisage the application of a set of filters to the output of a microphone (or any other signal) during a live performance. The parameters may be controlled using faders, mice, joysticks, etc. via MIDI or any other protocol. The number of filters used in real-time is directly dependent on the processing power of the hardware and may therefore be reduced or increased in a modular way, making the process easily adaptable to the capabilities of a particular system.</p>			<p><b>Notes</b></p>			<ol>				<li>From the trigonometric identity cos(a)=cos(-a), one may conclude that negative frequencies reflect as positive frequencies with no change of phase.				<li>RMS is the square root of the average of samples raised to the square.			</ol>			<p><b>References</b></p>			<p>Atkins, M., Bentley, A., Endrich, T., Fischman, R., Malham, D., Orton, R. and Wishart, T. 1987. The Composers&#146; Desktop Project. In S. Tipei and J. Beauchamp (eds.) <i>Proc. Int. Computer Music Conf</i>. San Francisco: Computer Music Association, pp. 146-50</p>			<p>Dobson, R. and Endrich, T. J. 1994. CDP &#145;Groucho&#146; Sound Processing Programs. In T. J. Endrich (ed.) <i>Composers&#146; Desktop Project (CDP). Professional Computer Music System User Guide</i>, <i>Release 2</i>. York: CDP Ltd.</p>			<p>Dodge, C., Jerse, T. A. 1985. <i>Computer Music. Synthesis, Composition and Performance</i>. New York: Schirmer Books.</p>			<p>Fischman, R. 1991. <i>Musical Applications of Digital Synthesis and Processing Techniques. Realisation using Csound and the Phase Vocoder</i>. Unpublished addendum to DPhil composition folio. York University. UK.</p>			<p>Fischman, R. 1994. Sound Processing in Los Dados Eternos. In N. Osborne, P. Nelson, S. Emmerson (eds.) <i>Contemporary Music Review. Timbre Composition in Electroacoustic Music</i>. <b>10</b>(2): 181-9. Switzerland: Harwood.</p>			<p>Fischman, R. 1995. <i>The Day After</i>. Piece for string quartet and tape.</p>			<p>Risset J. C. 1969. <i>Introductory Catalogue of Computer-Synthesized Sounds</i>. Murray Hill, N. J.: Bell Telephone Laboratories.</p>			<p>Risset J. C. 1977. <i>Inharmonique</i>. In compact disc INA C003.</p>			<p>Risset J. C. 1985. <i>Sud</i>. In compact disc INA C003.</p>			<p>Risset J. C. 1991. Timbre analysis by Synthesis. Representations, Imitations, and Variants for Musical Composition. In G. De Poli, A. Picciali and C. Roads (eds.) <i>Representations of Musical Signals</i>, pp. 7-43. Cambridge, MA: MIT Press.</p>			<p>Vercoe, B. 1986. <i>Csound. A Manual for the Audio Processing System and Supporting Programs with Tutorials</i>. Cambridge, MA: MIT Media Lab.</div>	</body></html>