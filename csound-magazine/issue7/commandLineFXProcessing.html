<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>

<title>Csound Journal</title>
<link href="commandline.css" rel="stylesheet" type="text/css">
</head>


<body>
<div id="wrap">
<div id="navigation"> CSOUND JOURNAL: <a href="../index.html">Home</a>
|&nbsp;<a href="index.html">Issue 7</a> </div>

<div id="header">
<h2>Command Line FX Processing</h2>
Jacob Joaquin<br>
jacobjoaquin AT gmail.com
</div>

<div id="content">



<!--
FX Processor examples:

	Shellverb
	Chorus
	Reverse
	Stretch

Credits:
	Peiman for the idea
	Andres Cabrera for the --omacro: idea
	sand-6 for the ${%i.*} idea
-->





<h2>Introduction</h2>

<p>Csound has proven time and time again that it is not only extremely powerful, but also extremely versatile.  One example of its versatility that is often overlooked is its ability to be used as a command line digital-signal-processor.</p>

<p>Much like how the command line utility Image Magick[<a href="index.html#References">1</a>] can be used to generate and process image files, Csound csd files can be specifically designed for the sole purpose of processing audio files.  The goal of this article is to present two working Csound FX processor models, discuss in detail every significant component, describe the reasoning for the designs, and demonstrate methods for solving the issues that arise when using Csound in this way.</p>








<h2 id="Overview">I. Overview</h2>

<h3 id="">The Command Line</h3>

<p>A command line[<a href="index.html#References">2</a>] is a text-based user interface.  A user types in a sequence of letters, numbers and other symbols to instruct the computer to do a specific task.  Many Csounders are familiar with at least one of the Csound graphical-user interface applications such as MacCsound[<a href="index.html#References">3</a>] or Csound5GUI[<a href="index.html#References">4</a>].  Applications like these are front end versions of the command line version.</p>

<pre id="Figure1.0">csound [-flags] csdfile
csound [-flags] orchfile scorefile</pre>

<div id="figure"><b>Figure 1.0</b>&nbsp;&nbsp;&nbsp;&nbsp;The basic structure of a valid command line call to Csound.</div>




<p>The following example demonstrates how to render a Csound csd file at the command prompt:</p>


<pre id="Figure1.1">$ csound -A -oblip.aif blip.csd</pre>

<div id="figure"><b>Figure 1.1</b>&nbsp;&nbsp;&nbsp;&nbsp;This command line instruction renders the audio file blip.aif.</div>




For more information about running Csound from a command prompt, type the following:

<pre id="Figure1.2">$ csound --help</pre>

<div id="figure"><b>Figure 1.2</b>&nbsp;&nbsp;&nbsp;&nbsp;This will output a list of all the legal Csound flags and options.</div>







<h3 id="">Processing an Audio File</h3>

<p>The syntax to process a user-specified audio file from the command is slightly more involved than just rendering a standard csd or orc-sco pair.  Since these csd processors are generically designed, meaning that the file or files to be processed are unknown, the name of the input file must be supplied to Csound at the command prompt.  The following example demonstrates processing a file named "input.aif" and outputting a file named "output.aif":


<pre id="Figure1.3">$ csound -d -A -ooutput.aif --omacro:Filename=input.aif BasicVerb.csd</pre>

<div id="figure"><b>Figure 1.3</b>&nbsp;&nbsp;&nbsp;&nbsp;How to invoke a Csound fx processor with the command line.</div>



<p>If you are not used to using Csound in this manner, or have little experience with a command prompt, the syntax may look like a foreign language.  The following list breaks everything down into single instructions, and describes their purpose:

<p><code>$</code>&nbsp;&nbsp;&nbsp;&nbsp;This represents the command prompt.  The prompt on you system will most likely look different.  You do not need to type this.</p>
<p><code>csound</code>&nbsp;&nbsp;&nbsp;&nbsp;This is the Csound application.</p>

<p><code>-d</code>&nbsp;&nbsp;&nbsp;&nbsp;"suppress all displays"</p>

<p><code>-A</code>&nbsp;&nbsp;&nbsp;&nbsp;"create an AIFF format output soundfile"</p>

<p><code>-o</code>&nbsp;&nbsp;&nbsp;&nbsp;"fnam sound output filename"  aka, the output name flag.</p>

<p><code>output.aif</code>&nbsp;&nbsp;&nbsp;&nbsp;This is the audio file that will be created by Csound.  If output.aif already exists, it will be overwritten.</p>

<p><code>--omacro:XXX=YYY</code>&nbsp;&nbsp;&nbsp;&nbsp;"Set orchestra macro XXX to value YYY"</p>

<p><code>Filename</code>&nbsp;&nbsp;&nbsp;&nbsp;This is the name of the input file that will be processed by BasicVerb.csd.  This macro is specific to BasicVerb.csd, and is not part of the default Csound flags.</p>

<p><code>input.aif</code>&nbsp;&nbsp;&nbsp;&nbsp;This is the audio file which will be processed.</p>

<p><code>BasicVerb.csd</code>&nbsp;&nbsp;&nbsp;&nbsp;This is the fx processor csd file.</p>







<h3 id="">Preview Before you Write</h3>

<p>Instead of writing to a file, you can send the audio directly to the digital-to-audio converter (DAC) and preview the results before committing the processed audio to a file.  To do this, output to the DAC with <code>-odac</code>.</p>


<pre id="Figure1.4">$ csound -d -odac --omacro:Filename=input.aif --omacro:Diffusion=0.5 FlexiVerb.csd</pre>

<div id="figure"><b>Figure 1.4</b>&nbsp;&nbsp;&nbsp;&nbsp;Preview the output of the FX processor before you create the file.</div>







<h3 id="">The Flow</h3>

<p>This entire system of processing files can be broken into three generalized stages.  The first stage involves executing Csound at the command prompt.  During stage two, Csound processes an audio file.  The third stage is the processed audio output file.  In real world applications, these details can change.  For example, the output might be several files.


<p id="Figure1.5"><center><img src="images/commandLineFXProcessing/generalflow.png" width=270px height=229px></center></p>
<div id="figure"><b>Figure 1.5</b>&nbsp;&nbsp;&nbsp;&nbsp;From the command prompt to the audio file.</div>






<h3 id="">Batch Processing with BASH</h3>

<p>Many command line shells, such as the Bourne-again Shell (BASH), come with tools that can turn a Csound FX processor into a batch processor.   Doing this requires a few more instructions at the command prompt.  The following BASH commands show how to create a directory named <code>./outputDir/</code>, process every AIF file in the current directory, and write the processed files to <code>./outputDir/</code>.<p>

<p><b>WARNING</b>:  Use at own risk, as this method will overwrite any existing files of the same names in ./outputDir/.</p>

<pre id="Figure1.6">$ mkdir outputDir
$ for i in *.aif ; do csound -d -A -o./outputDir/${i%.*}_fx.aif \
  --omacro:Filename=$i FlexiVerb.csd ; done</pre>

<div id="figure"><b>Figure 1.6</b>&nbsp;&nbsp;&nbsp;&nbsp;Batch process every AIF file in current directory, and write the output files to the ./outputDir/ folder.</div>

<p>BASH is a common shell found on many linux and unix derivatives, including the Terminal.app in OS X.  For users of Windows, Cygwin[<a href="index.html#References">5</a>] offers much of the same functionality offered in many native *nix like operating systems.</p>


















<h2 id="mahid">II. BasicVerb - A Simple FX Processor Model</h2>

<p><a href="BasicVerb.csd.txt">BasicVerb</a> is a specially prepared csd file designed to process mono audio files specified by the user on the command prompt.  Though BasicVerb lacks many useful features, it does contain all the necessary bare-bone elements required to be used as a fully functioning FX processor.</p>






<h3 id="">Flow</h3>

When Csound is executed, control of the file starts in the score.  The score quickly passes control to the <code>Setup</code> instrument in the orchestra.  Setup is responsible of initializing the FX engine.  The <code>Process</code> instrument is started by <code>Setup</code>, adds reverb to the input file, and outputs a new file.

<p id="Figure2.0"><center><img src="images/commandLineFXProcessing/BasicVerbFlow.png" width=383px height=486px></center></p>
<div id="figure"><b>Figure 2.0</b>&nbsp;&nbsp;&nbsp;&nbsp;BasicVerb flow.</div>








<h3 id="">The Score Line</h3>

<p>The score has the sole function of starting the FX processor.  This is accomplished with a single score line that calls the <code>Setup</code> instrument.  The rest of the work is handled exclusively by the orchestra.</p>


<pre id="Figure2.1">i Setup 0 0.0001  ; Start processor</pre>

<div id="figure"><b>Figure 2.1</b>&nbsp;&nbsp;&nbsp;&nbsp;This single line of score code starts the Fx Processor.</div>


<p>The duration of this call has been set 0.0001.  The reason such a low duration is chosen is to reduce unnecessary muted space at the end of the output file.</p>





<h3 id="">Sample Rates and Channels</h3>

<p>Since the standard sample rate of Red Book audio[<a href="index.html#References">6</a>] is 44.1kHz, the decision to set BasicVerb's <code>sr</code> to 44100 seems natural.  Since processing files is more about doing non-real-time work rather than real-time performance, setting <code>kr</code> to 44100 makes sense as it will produce the best audio quality when k-rate signals are used.</p>

<pre id="Figure2.2">sr     = 44100
kr     = 44100
ksmps  = 1
nchnls = 1</pre>

<div id="figure"><b>Figure 2.2</b>&nbsp;&nbsp;&nbsp;&nbsp;Set the sample and control rate to 44.1kHz.</div>


<p>There will be times when using a different sample rate other than 44.1kHz is preferable.  Csound comes equipped with two flags, <code>-r</code> and <code>-k</code>, that allow the user to set the sample and control rates, avoiding the need to change the values of <code>sr</code> and <code>kr</code> in the orchestra header.</p>

<pre id="Figure2.3">csound -d -A -ooutput.aif --omacro:Filename=input.aif -r 96000 -k 96000 BasicVerb.csd</pre>

<div id="figure"><b>Figure 2.3</b>&nbsp;&nbsp;&nbsp;&nbsp;This overrides the sample and control rates listed in the orchestra header, and sets them to 96kHz.</div>











<h3 id="">Macro Parameters</h3>

<p>Macro definitions are used to store the parameters of the FX processor.  They are located near the top of the orchestra, and provide easy access for a user to make changes without having to dig through the code.</p>


<pre id="Figure2.4">; Filename           # ??? #  ; Name of file to process.  Required parameter,
                              ; supplied by user at the command prompt call.

# define Amp         # 1.0 #  ; Scales final amplitude, in case of clipping.
# define Mix         # 0.5 #  ; Dry / Wet mix.  0.0 = Dry, 1.0 = Wet.
# define ReverbTime  # 1.0 #  ; Time of the reverb.</pre>

<div id="figure"><b>Figure 2.4</b>&nbsp;&nbsp;&nbsp;&nbsp;Macros are used for parameters.</div>

<p>The downside to this implementation is that these macros are hardwired in the code.  Csound's macro system does provide a solution that allow macros to be set by the user an the command prompt.   See <code>#ifndef</code>.</p>












<h3 id="">Setup Instrument</h3>

<p>The <code>Setup</code> instrument is the brain of the FX processor, as <code>Setup</code>'s job is to prepare the Fx processor engine with all the necessary details.  In this model, <code>Setup</code> calculates the duration of the output and turns on the Processor instrument.  <code>Setup</code> does all of its work at initialization, and uses the <code>turnoff</code> opcode when finished.

<p>One significant issue when designing a generic FX processor is that the duration of the input file can and will be different between uses.  Another issue is that some digital signal processes will change the duration of the output file, such as a reverb tail.</p>




<h4 id="">Calculating the Duration</h4>

<p>In order to solve the problem of the unknown file input duration, <code>Setup</code> and <code>Process</code> handle different tasks.  <code>Setup</code> calculates the duration of the output file by getting the length of the input file and adding this with the reverb time.</p>

<pre id="Figure2.5">ilength   filelen "$Filename"            ; Length of file in seconds
iduration =       ilength + $ReverbTime  ; Calculate duration of output file</pre>

<div id="figure"><b>Figure 2.5</b>&nbsp;&nbsp;&nbsp;&nbsp;Calculate the duration of the output file.</div>







<h4 id="">Starting the Processor</h4>

<p>Now that the duration is known, it is used in conjunction with the <code>event_i</code> to turn on the <code>Process</code> instrument.</p>

<pre id="Figure2.6">event_i "i", "Process", 0, iduration</pre>

<div id="figure"><b>Figure 2.6</b>&nbsp;&nbsp;&nbsp;&nbsp;This starts the <code>Processor</code> instrument.</div>










<h3 id="">Processor</h3>

<p>If <code>Setup</code> is the brain, then <code>Processor</code> is clearly the heart.  This is where the input file is transformed.  Since <code>Setup</code> takes care of the logistics of making Csound work as a command line based FX processor, <code>Processor</code> is designed as if it were a typical Csound instrument.</p>




<h4 id="">Sample Rate and Pitch</h4>

<p>The only significant issue at this stage is that a difference between the sample rate of the orchestra and that of the input file could cause a transposition of pitch.  The <code>diskin</code> opcode accepts an optional parameter that alters the pitch of the file.  To adjust for possible differences in samples rate, dividing the sample rate of the file by the sample rate of the orchestra will yield the proper ratio, correcting the pitch.</p>



<pre id="Figure2.7">ifilesr filesr "$Filename"                ; Get samplerate of file
ain     diskin "$Filename", ifilesr / sr  ; Read file from disk</pre>

<div id="figure"><b>Figure 2.7</b>&nbsp;&nbsp;&nbsp;&nbsp;Adjust for potential differences in sample rate.</div>


<p>This method is a bit crude, as files with higher sample rates played back at lower samples rates may introduce audible aliasing[<a href="index.html#References">7</a>] to the final product.</p>














<h4 id="">Output</h4>

<p>Once the Csound job is finished, your freshly processed file is waiting for you to listen.</p>


















<h2 id="mahid">III. FlexiVerb - A Flexible FX Processor Model</h2>

<p><a href="FlexiVerb.csd.txt">FlexiVerb</a> improves on the BasicVerb model by including a couple of features that improve flexibility for the user:</p>
<ul>
<li>Parameters can be set at the command prompt.
<li>The processor will accept both mono and stereo files.
</ul>
<p>Along with these additions comes a major design differences in the instrument model.</p>







<h3 id="">Flow</h3>

<p>FlexiVerb's instrument model has extra complexity that allows the FX processor to accept both mono and stereo audio files.  There are four instruments in this model:  <code>Setup</code>, <code>Input</code>, <code>Process</code> and <code>Output</code>.</p>

<p>The score line is still the entry point to the FX processor, and does this by calling the <code>Setup</code> instrument.  <code>Setup</code> has a more prominent role in the design as it is responsible for starting the other three instruments, routing the zak signals, and declaring f-tables to store the audio input file.</p>


<p id="Figure3.0"><center><img src="images/commandLineFXProcessing/FlexiVerbFlow.png" width=416px height=686px></center></p>
<div id="figure"><b>Figure 3.0</b>&nbsp;&nbsp;&nbsp;&nbsp;FlexiVerb flow.</div>










<h3 id="">Stereo Output</h3>

<p>FlexiVerb always outputs a stereo file, whether or not the input audio file is mono or stereo.  Since it is a stereo reverb, <code>nchnls</code> is set to 2 in the header.</p>









<h3 id="">Parameters with #ifndef</h3>

<p>With the help of the <code>#ifndef</code>, parameters are defined with a default value that can be overridden manually with the <code>--omacro</code> at the command prompt.  FlexiVerb is equipped with six parameters.  If they are not specified by the user at the command line, then their default values are used.</p>

<pre id="Figure3.1">; Filename           # ??? #  ; Name of file to process.  Required parameter,
                              ; supplied by user at the command prompt call.


# ifndef Amp
# define Amp         # 1 #    ; Master amplitude
# end

# ifndef Mix
# define Mix         # 0.1 #  ; Dry / Wet mix.
# end

# ifndef Time1
# define Time1       # 1 #    ; Reverb time for left channel.
# end

# ifndef Time2
# define Time2       # 1 #    ; Reverb time for right channel.
# end

# ifndef Diffusion1
# define Diffusion1  # 0 #    ; High frequency diffusion for left channel.
# end

# ifndef Diffusion2
# define Diffusion2  # 0 #    ; High frequency diffusion for right channel.
# end</pre>

<div id="figure"><b>Figure 3.1</b>&nbsp;&nbsp;&nbsp;&nbsp;FlexiVerb is equipped with six parameters: Amp, Mix, Time1, Time2, Diffusion1 and Diffusion2.</div>

<p>The following command call overrides the <code>Mix</code> parameter with the value of 0.2.  The other four parameters will assume their default values.</p>

<pre id="Figure3.2">$ csound -d -o./Output.aif --omacro:Filename=./Input.aif --omacro:Mix=0.2 FlexiVerb.csd</pre>

<div id="figure"><b>Figure 3.2</b>&nbsp;&nbsp;&nbsp;&nbsp;The <code>Mix</code> parameter has the value of 0.2 instead of the default value of 0.1.</div>








<h3 id="">Zak Bus</h3>

<p>The instruments <code>Input</code>, <code>Process</code>, and <code>Output</code> require a method of passing and accepting audio between one another.  The zak bus system was chosen for its simplicity and ability to reference channels by number.  The following code initializes the two a-rate zak channels required to handle the stereo bus.</p>


<pre id="Figure3.3">zakinit 2, 1</pre>

<div id="figure"><b>Figure 3.3</b>&nbsp;&nbsp;&nbsp;&nbsp;Create two a-rate zak channels.</div>









<h3 id="">Setup</h3>


<p><code>Setup</code> has a hand in almost every task in this design model.  The other three instruments are relatively simple in comparison.</p>





<h4 id="">Input File Information</h4>

<p>In order for <code>Setup</code> to accomplish all of its various tasks, it must collect information about the audio input file.  This information includes:  the length of the file, the number of channels, the sample rate and number of samples.</p>

<pre id="Figure3.4">ilength  filelen    "$Filename"    ; Length of file in seconds
inchnls  filenchnls "$Filename"    ; Number of channels
isr      filesr     "$Filename"    ; Sample rate of file
isamples =          ilength * isr  ; Number of samples in file, per channel</pre>

<div id="figure"><b>Figure 3.4</b>&nbsp;&nbsp;&nbsp;&nbsp;This collects information about the audio input file to be processed.</div>







<h4 id="">Calculating the Duration</h4>

In order to calculate the duration of the output file, the times of the reverbs are compared to one another to get the longer duration of the two.  The longer duration is then added to the length of the input file.  The following code demonstrations how this is accomplished using a conditional statement.</p>

<pre id="Figure3.5">iduration = ( $Time1 > $Time2 ? $Time1 : $Time2 ) + ilength</pre>

<div id="figure"><b>Figure 3.5</b>&nbsp;&nbsp;&nbsp;&nbsp;Checks which reverb is longer, adds this to the length of the file, calculating the duration of the output file.</div>











<h4 id="">F-tables</h4>

<p>The <code>diskin</code> opcode is traded out in favor of pre-loading the audio file into one or two f-tables.  The reason for such a radical design change is because <code>diskin</code> is limited in the way it can stream files from disc.  It can load either the left channel or the left and right channels, but not the right channel by itself.</p>

<p>Since f-tables can be generated dynamically, specifiable by a number, and can be read one at a time, they work perfectly with this model.  Though you should be aware of two issues.  First, since FX processors are generically programmed to handle files of any size, the size of a file is always unknown when executed.  Second, tables require their memories to be declared as a size of a power-of-two or a power-of-two plus one.<p>

<p>At this point in the <code>Setup</code> instrument, the length of the audio file is known.  See Input File Information.  The next thing to do is to calculate the size of the table or tables that are to be generated.  The following loop code continually doubles <code>isize</code> until the value is greater than the number of samples, per channel, in the audio input file.</p>

<pre id="Figure3.6">isize = 1
repeat:
    isize = isize * 2
if( isize < isamples ) goto repeat
isize = isize + 1</pre>

<div id="figure"><b>Figure 3.6</b>&nbsp;&nbsp;&nbsp;&nbsp;Calculate size of the f-table(s).</div>






<h4 id="">Conditional Branching: Mono or Stereo?</h4>

An <code>if</code> conditional branch is used to execture the proper block of code based on whether the input file was mono or stereo.

<pre id="Figure3.7">if( inchnls == 2 ) igoto inputStereo</pre>

<div id="figure"><b>Figure 3.7</b>&nbsp;&nbsp;&nbsp;&nbsp;Conditional branching.</div>

<p>For more information about conditional branching, read Steven Yi's articles[<a href="index.html#References">8</a>,<a href="index.html#References">9</a>] on conditional branching.</p>







<h4 id="">Loading a Mono Sample</h4>

<p>For a mono file, only one table needs to be created.  The <code>ftgen</code> opcode creates this single f-table at index one, and loads in the sample using the <code>GEN 01</code> routine.  An event for <code>Input</code> is generated.  The third parameter is the length of time that the sample is to be played.  Parameters four and five take arguments for which f-tables will be used for the left and right channel.  Since a mono file is to be processed, both of these parameters are given f-table index 1.</p>

<pre id="Figure3.8">inputMono:

    ; Load Sample into table
    
    gitemp ftgen 1, 0, isize, 1, "$Filename", 0, 0, 1



    ; Play Sample

    event_i "i", "Input", 0, ilength, 1, 1</pre>

<div id="figure"><b>Figure 3.8</b>&nbsp;&nbsp;&nbsp;&nbsp;A single table is created, and then this table is fed to both f-table inputs in the <code>event_i</code> call to instrument Input.</div>










<h4 id="">Loading a Stereo Sample</h4>

Two f-tables are created and then loaded with the contents of the stereo input file.  The fifth parameter of the <code>event_i</code> differs as it is passed f-table two, as it stores the contents of the right channel of the input audio file.

<pre id="Figure3.9">inputStereo:

    ; Load Sample into stereo table pair
    
    gitemp ftgen 1, 0, isize, 1, "$Filename", 0, 0, 1    
    gitemp ftgen 2, 0, isize, 1, "$Filename", 0, 0, 2    



    ; Play Sample

    event_i "i", "Input", 0, ilength, 1, 2</pre>

<div id="figure"><b>Figure 3.9</b>&nbsp;&nbsp;&nbsp;&nbsp;Two f-table are created, and then fed to the f-table inputs in the <code>event_i</code> call to instrument Input.</div>









<h4 id="">Starting the Processor</h4>

<p>Starting <code>Processor</code> is fairly straight forward, as it is akin to starting a typical zak based FX processor found in many Csound files.</p>

<pre id="Figure3.10">event_i "i", "Process", 0, iduration</pre>

<div id="figure"><b>Figure 3.10</b>&nbsp;&nbsp;&nbsp;&nbsp;Start the Processor.</div>







<h4 id="">Starting the Output</h4>

<p>The last item on <code>Setup</code>'s list is to start the <code>Output</code> instrument, which is responsible for writing the audio to a file or to the DAC.</p>
	
<pre id="Figure3.11">event_i "i", "Output", 0, iduration</pre>

<div id="figure"><b>Figure 3.11</b>&nbsp;&nbsp;&nbsp;&nbsp;Start the Output.</div>












<h3 id="">Input</h3>

<p>The <code>Input</code> instrument does two things.  The first is to read the audio samples from the f-table or f-tables.</p>

<pre id="Figure3.12">aphasor phasor 1 / idur
asig1   table3 aphasor * isamples, ifn1, 0
asig2   table3 aphasor * isamples, ifn2, 0</pre>

<div id="figure"><b>Figure 3.12</b>&nbsp;&nbsp;&nbsp;&nbsp;Read audio from the f-table(s).</div>

The second is to stream this audio to zak bus channels one and two.

<pre id="Figure3.13">zaw asig1, 1
zaw asig2, 2</pre>

<div id="figure"><b>Figure 3.13</b>&nbsp;&nbsp;&nbsp;&nbsp;Stream the audio to zak channels 1 and 2.</div>









<h3 id="">Process</h3>

<p>The <code>Process</code> instrument reads audio from the two zak channels, sends them through the <code>reverb2</code> opcodes, mixes the dry and wet signals, and writes the audio back to the two zak channels.</p>







<h3 id="">Output</h3>

<p>The <code>Output</code> instrument is the final stage.  It reads in the audio from the two zak channels, makes any adjustments to the volume, based on the Amp parameter, and sends the audio to the output file or DAC.</p>











<h2 id="mahid">IV. And Beyond...</h2>


The two models and associated methods I have presented should help get you on your way to designing and implementing command line based Csound FX processors.  Though the examples are merely rudimentary reverb units, they lay the basic foundation for which much more interesting FX units can be written.  All of Csound's tools can be used at your discretion to invent whatever your imagination can come up with.  Happy Csounding.





<h2 id="Acknowledgments">Acknowledgments</h2>

<p>I want to thank peiman for the inspiration for this article.  He had originally asked the Csound mailing list[<a href="index.html#References">10</a>] if it was possible to use Csound as a batch processor, which led to the development of many of the methods containted in this article.  I would like to thank Andres Cabrera for suggesting in the same mailing list thread[<a href="index.html#References">11</a>] about using the <code>--omacro</code> flag for passing parameters to Csound at the command prompt.  I would also like to thank sand-6 for streamlining[<a href="index.html#References">12</a>] the BASH batch processor instructions.  Finailly, I would like to thank the editors James Hearon and Steven Yi for giving me an extra week to write this article during a very busy period of my life.</p>

<p>Best,<br>
Jacob Joaquin</p>




<h3 id="Files">Files</h3>
<a href="CommandLineFX.zip">CommandLineFX.zip</a> - All the related files for this article.</a><br>



<h3 id="Links">Links</h3>
<a href="http://www.csounds.com/">Csounds.com</a> - ... almost everything Csound.<br>
<a href="http://www.csounds.com/journal/">Csound Journal</a> - Inspiration in Ezine form.</a><br>
<a href="http://www.thumbuki.com/csound/blog/">The Csound Blog @ Thumbuki</a> - The Csound Blog is a collection of journals that are distributed within unified Csound csd files.<br>
<a href="http://www.thumbuki.com/">Thumbuki.com</a> - The Cosmos in 20 Words or Less.<br>






<h3 id="References">References</h3>

[1] Image Magick. <a href="http://www.imagemagick.org/">http://www.imagemagick.org/script/index.php</a><br>

[2] Command Line Interface @ Wikipedia. <a href="http://en.wikipedia.org/wiki/Command_line_interface">http://en.wikipedia.org/wiki/Command_line_interface</a><br>

[3] MacCsound. <a href="http://www.csounds.com/matt/MacCsound/">http://www.csounds.com/matt/MacCsound/</a><br>

[4] Csound5GUI. <a href="http://csound.sourceforge.net/">http://csound.sourceforge.net/</a><br>

[5] Cygwin. <a href="http://www.cygwin.com/">http://www.cygwin.com/</a><br>

[6] Red Book @ Wikipedia. <a href="http://en.wikipedia.org/wiki/Red_Book_Audio">http://en.wikipedia.org/wiki/Red_Book_Audio</a><br>

[7] Nyquist frequency @ Wikipedia. <a href="http://en.wikipedia.org/wiki/Nyquist_frequency">http://en.wikipedia.org/wiki/Nyquist_frequency</a><br>

[8] Control Flow - Part I by Steven Yi. <a href="http://www.csounds.com/journal/2006spring/controlFlow.html">http://www.csounds.com/journal/2006spring/controlFlow.html</a><br>

[9] Control Flow - Part II by Steven Yi. <a href="http://www.csounds.com/journal/2006summer/controlFlow_part2.html">http://www.csounds.com/journal/2006summer/controlFlow_part2.html</a><br>

[10] Csound Mailing List: Batch processing audio-files with csound(?) by peiman. <a href="http://www.nabble.com/Batch-processing-audio-files-with-csound%28-%29-p11479592.html">http://www.nabble.com/Batch-processing-audio-files-with-csound%28-%29-p11479592.html</a><br>

[11] Csound Mailing List: Batch processing audio-files with csound(?) by Andres Cabrera. <a href="http://www.nabble.com/Re%3A-Batch-processing-audio-files-with-csound%28-%29-p11479708.html">http://www.nabble.com/Re%3A-Batch-processing-audio-files-with-csound%28-%29-p11479708.html</a><br>

[12] Csound Mailing List: Batch processing audio-files with csound(?) by sand-6. <a href="http://www.nabble.com/Re%3A-Batch-processing-audio-files-with-csound%28-%29-p11482858.html">http://www.nabble.com/Re%3A-Batch-processing-audio-files-with-csound%28-%29-p11482858.html</a><br>


</div>
</div>
</body>
</html>
